{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Audio Transcription - FIXED VERSION\n",
    "### Handles both \"first\" and \"1st\" keyword formats\n",
    "\n",
    "**Instructions:**\n",
    "1. Upload audio_task_43.mp3 to your Google Drive\n",
    "2. Enable GPU: Runtime ‚Üí Change runtime type ‚Üí T4 GPU\n",
    "3. Run all cells\n",
    "\n",
    "**Time:** ~60-90 minutes for full transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Whisper\n",
    "!pip install -q openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö† WARNING: Enable GPU in Runtime ‚Üí Change runtime type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Update this path if needed\n",
    "audio_file = \"/content/drive/MyDrive/audio_task_43.mp3\"\n",
    "\n",
    "if os.path.exists(audio_file):\n",
    "    print(f\"‚úì Found: {audio_file}\")\n",
    "    print(f\"  Size: {os.path.getsize(audio_file) / (1024**2):.1f} MB\")\n",
    "else:\n",
    "    print(f\"‚ö† Searching for audio_task_43.mp3...\")\n",
    "    import subprocess\n",
    "    result = subprocess.run(['find', '/content/drive/MyDrive', '-name', 'audio_task_43.mp3'],\n",
    "                          capture_output=True, text=True, timeout=60)\n",
    "    files = [f for f in result.stdout.strip().split('\\n') if f]\n",
    "    if files:\n",
    "        audio_file = files[0]\n",
    "        print(f\"‚úì Found at: {audio_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configuration\nCHUNK_DURATION_MIN = 10  # 10-minute chunks\nTOTAL_DURATION_MIN = 470  # 7h50min\n\nimport whisper\nimport subprocess\nimport re\nimport time\n\n# Create output directories\nos.makedirs('audio_chunks', exist_ok=True)\nos.makedirs('transcriptions', exist_ok=True)\nprint(\"‚úì Created output directories: audio_chunks/ and transcriptions/\")\n\n# Load model\nprint(\"Loading Whisper 'base' model...\")\nmodel = whisper.load_model(\"base\")\nprint(f\"‚úì Model on {'GPU' if next(model.parameters()).is_cuda else 'CPU'}\")\n\nnum_chunks = (TOTAL_DURATION_MIN + CHUNK_DURATION_MIN - 1) // CHUNK_DURATION_MIN\nprint(f\"\\nWill process {num_chunks} chunks of {CHUNK_DURATION_MIN} minutes each\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal word mapping (FIXED!)\n",
    "ordinal_map = {\n",
    "    'first': 1, 'second': 2, 'third': 3, 'fourth': 4, 'fifth': 5,\n",
    "    'sixth': 6, 'seventh': 7, 'eighth': 8, 'ninth': 9, 'tenth': 10,\n",
    "    'eleventh': 11, 'twelfth': 12, 'thirteenth': 13, 'fourteenth': 14,\n",
    "    'fifteenth': 15, 'sixteenth': 16, 'seventeenth': 17, 'eighteenth': 18,\n",
    "    'nineteenth': 19, 'twentieth': 20\n",
    "}\n",
    "\n",
    "def find_keywords(text):\n",
    "    \"\"\"Find keywords - handles both 'first' and '1st' formats\"\"\"\n",
    "    # Pattern matches BOTH word ordinals AND numeric ordinals\n",
    "    pattern = r\"[Tt]he\\s+(first|second|third|fourth|fifth|sixth|seventh|eighth|ninth|tenth|eleventh|twelfth|thirteenth|fourteenth|fifteenth|sixteenth|seventeenth|eighteenth|nineteenth|twentieth|\\d+(?:st|nd|rd|th)?)\\s+letter\\s+(?:in|of)\\s+(?:the\\s+)?keyword\\s+is\\s+([A-Za-z])[,.\\s]+([A-Za-z]+)\"\n",
    "    \n",
    "    matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "    \n",
    "    results = []\n",
    "    for ordinal, letter, phonetic in matches:\n",
    "        # Convert word ordinals to numbers\n",
    "        if ordinal.lower() in ordinal_map:\n",
    "            pos_num = ordinal_map[ordinal.lower()]\n",
    "        else:\n",
    "            # Extract number from numeric ordinal (1st, 2nd, etc)\n",
    "            pos_num = int(re.sub(r'[^\\d]', '', ordinal))\n",
    "        \n",
    "        results.append((pos_num, letter.upper(), phonetic))\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"‚úì Keyword search function ready (handles both formats)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Process all chunks\nall_keywords = {}\nkeyword_locations = {}\n\nprint(\"=\"*70)\nprint(f\"Processing {num_chunks} chunks with FIXED keyword detection\")\nprint(\"=\"*70)\n\nstart_time = time.time()\n\nfor i in range(num_chunks):\n    start_min = i * CHUNK_DURATION_MIN\n    start_sec = start_min * 60\n    duration_sec = CHUNK_DURATION_MIN * 60\n    \n    chunk_file = f\"audio_chunks/chunk_{i:03d}.mp3\"\n    transcript_file = f\"transcriptions/chunk_{i:03d}.txt\"\n    \n    print(f\"\\n[{i+1}/{num_chunks}] Minutes {start_min}-{start_min+CHUNK_DURATION_MIN}\")\n    \n    # Extract chunk\n    if not os.path.exists(chunk_file):\n        cmd = ['ffmpeg', '-y', '-v', 'quiet', '-ss', str(start_sec),\n               '-i', audio_file, '-t', str(duration_sec),\n               '-acodec', 'libmp3lame', chunk_file]\n        subprocess.run(cmd, check=True)\n    \n    # Transcribe\n    result = model.transcribe(chunk_file, verbose=False, fp16=torch.cuda.is_available())\n    transcript = result[\"text\"]\n    \n    # Save transcription to file\n    with open(transcript_file, 'w', encoding='utf-8') as f:\n        f.write(f\"Chunk {i} - Minutes {start_min}-{start_min+CHUNK_DURATION_MIN}\\n\")\n        f.write(\"=\"*70 + \"\\n\\n\")\n        f.write(transcript)\n    \n    # Search for keywords with FIXED pattern\n    matches = find_keywords(transcript)\n    \n    if matches:\n        print(f\"  ‚úì‚úì‚úì FOUND {len(matches)} KEYWORD(S)! ‚úì‚úì‚úì\")\n        for pos_num, letter, phonetic in matches:\n            all_keywords[pos_num] = letter\n            keyword_locations[pos_num] = {\n                'letter': letter,\n                'phonetic': phonetic,\n                'chunk': i,\n                'time_min': start_min\n            }\n            print(f\"      Position {pos_num}: {letter} ({phonetic})\")\n    else:\n        snippet = transcript[:60].replace('\\n', ' ')\n        print(f\"  - No keywords (sample: {snippet}...)\")\n    \n    print(f\"  üíæ Saved: {chunk_file} and {transcript_file}\")\n    \n    # Progress every 5 chunks\n    if (i + 1) % 5 == 0:\n        elapsed = (time.time() - start_time) / 60\n        avg_time = elapsed / (i + 1)\n        remaining = avg_time * (num_chunks - i - 1)\n        print(f\"\\n  ‚è± Progress: {i+1}/{num_chunks} | {elapsed:.1f}m elapsed | ~{remaining:.1f}m remaining\")\n        print(f\"  üîë Keywords found: {len(all_keywords)}\")\n\ntotal_time = (time.time() - start_time) / 60\nprint(f\"\\n{'='*70}\")\nprint(f\"‚úì Completed in {total_time:.1f} minutes\")\nprint(f\"‚úì Audio chunks saved to: audio_chunks/\")\nprint(f\"‚úì Transcriptions saved to: transcriptions/\")\nprint(f\"{'='*70}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if all_keywords:\n",
    "    print(f\"\\n‚úì Found {len(all_keywords)} keyword letters:\\n\")\n",
    "    \n",
    "    for pos in sorted(all_keywords.keys()):\n",
    "        loc = keyword_locations[pos]\n",
    "        print(f\"  Position {pos}: {loc['letter']} ({loc['phonetic']}) - at {loc['time_min']} min\")\n",
    "    \n",
    "    # Build keyword\n",
    "    max_pos = max(all_keywords.keys())\n",
    "    keyword = \"\"\n",
    "    for i in range(1, max_pos + 1):\n",
    "        keyword += all_keywords.get(i, \"_\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üö© KEYWORD: {keyword}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Check completeness\n",
    "    missing = [i for i in range(1, max_pos + 1) if i not in all_keywords]\n",
    "    if missing:\n",
    "        print(f\"\\n‚ö† Missing positions: {missing}\")\n",
    "        print(\"You may need to manually search for these in the audio.\")\n",
    "    else:\n",
    "        print(f\"\\n‚úì‚úì‚úì COMPLETE KEYWORD! ‚úì‚úì‚úì\")\n",
    "    \n",
    "    # Save solution\n",
    "    with open('SOLUTION.txt', 'w') as f:\n",
    "        f.write(f\"KEYWORD: {keyword}\\n\\n\")\n",
    "        f.write(\"Letters found:\\n\")\n",
    "        for pos in sorted(all_keywords.keys()):\n",
    "            loc = keyword_locations[pos]\n",
    "            f.write(f\"  Position {pos}: {loc['letter']} ({loc['phonetic']}) at {loc['time_min']} min\\n\")\n",
    "        if missing:\n",
    "            f.write(f\"\\nMissing positions: {missing}\\n\")\n",
    "    \n",
    "    print(\"\\n‚úì Solution saved to SOLUTION.txt\")\n",
    "    \n",
    "    # Download result\n",
    "    from google.colab import files\n",
    "    files.download('SOLUTION.txt')\n",
    "    print(\"\\n‚úì Downloaded SOLUTION.txt to your computer!\")\n",
    "else:\n",
    "    print(\"\\n‚ö† No keywords found. Check the audio file and pattern.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
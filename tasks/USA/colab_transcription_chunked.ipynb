{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU-Accelerated Chunked Audio Transcription\n",
    "### For AI Learning Marathon - USA Task\n",
    "\n",
    "**Why chunking?** The full 7h50min audio is too large to process at once (memory crash).\n",
    "\n",
    "**Solution:** Process in 10-minute chunks with GPU â†’ Fast & memory-efficient\n",
    "\n",
    "**Instructions:**\n",
    "1. Upload audio_task_43.mp3 to your Google Drive\n",
    "2. Enable GPU: Runtime â†’ Change runtime type â†’ GPU â†’ T4 GPU\n",
    "3. Run all cells\n",
    "\n",
    "**Estimated time:** 45-90 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"âš  No GPU! Enable it: Runtime â†’ Change runtime type â†’ GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Update this path if your file is in a different location\n",
    "audio_file = \"/content/drive/MyDrive/audio_task_43.mp3\"\n",
    "\n",
    "if os.path.exists(audio_file):\n",
    "    print(f\"âœ“ Found: {audio_file}\")\n",
    "    print(f\"  Size: {os.path.getsize(audio_file) / (1024**2):.1f} MB\")\n",
    "else:\n",
    "    print(f\"âš  Not found. Searching...\")\n",
    "    import subprocess\n",
    "    result = subprocess.run(['find', '/content/drive/MyDrive', '-name', 'audio_task_43.mp3'],\n",
    "                          capture_output=True, text=True, timeout=60)\n",
    "    files = [f for f in result.stdout.strip().split('\\n') if f]\n",
    "    if files:\n",
    "        audio_file = files[0]\n",
    "        print(f\"âœ“ Found at: {audio_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CHUNK_DURATION_MIN = 10  # Process 10 minutes at a time\n",
    "TOTAL_DURATION_MIN = 470  # 7h50min\n",
    "\n",
    "import whisper\n",
    "import subprocess\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Load model once\n",
    "print(\"Loading Whisper 'base' model (fast on GPU)...\")\n",
    "model = whisper.load_model(\"base\")\n",
    "print(f\"âœ“ Model loaded on {'GPU' if next(model.parameters()).is_cuda else 'CPU'}\")\n",
    "\n",
    "print(f\"\\nWill process {TOTAL_DURATION_MIN // CHUNK_DURATION_MIN} chunks of {CHUNK_DURATION_MIN} min each\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process audio in chunks\n",
    "import time\n",
    "\n",
    "all_keywords = {}\n",
    "keyword_locations = {}\n",
    "\n",
    "num_chunks = (TOTAL_DURATION_MIN + CHUNK_DURATION_MIN - 1) // CHUNK_DURATION_MIN\n",
    "print(\"=\"*70)\n",
    "print(f\"Processing {num_chunks} chunks...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(num_chunks):\n",
    "    start_min = i * CHUNK_DURATION_MIN\n",
    "    start_sec = start_min * 60\n",
    "    duration_sec = CHUNK_DURATION_MIN * 60\n",
    "    \n",
    "    chunk_file = f\"chunk_{i:03d}.mp3\"\n",
    "    \n",
    "    print(f\"\\n[{i+1}/{num_chunks}] Minutes {start_min}-{start_min+CHUNK_DURATION_MIN}\")\n",
    "    \n",
    "    # Extract chunk with ffmpeg\n",
    "    if not os.path.exists(chunk_file):\n",
    "        cmd = ['ffmpeg', '-y', '-v', 'quiet', '-ss', str(start_sec),\n",
    "               '-i', audio_file, '-t', str(duration_sec),\n",
    "               '-acodec', 'libmp3lame', chunk_file]\n",
    "        subprocess.run(cmd, check=True)\n",
    "    \n",
    "    # Transcribe chunk\n",
    "    result = model.transcribe(chunk_file, verbose=False, fp16=torch.cuda.is_available())\n",
    "    transcript = result[\"text\"]\n",
    "    \n",
    "    # Search for keywords\n",
    "    pattern = r\"[Tt]he\\s+(\\d+)(?:st|nd|rd|th)?\\s+letter\\s+(?:in|of)\\s+(?:the\\s+)?keyword\\s+is\\s+([A-Za-z])[,\\s]+([A-Za-z]+)\"\n",
    "    matches = re.findall(pattern, transcript)\n",
    "    \n",
    "    if matches:\n",
    "        print(f\"  âœ“âœ“âœ“ FOUND {len(matches)} KEYWORD(S)!\")\n",
    "        for pos, letter, phonetic in matches:\n",
    "            pos_num = int(pos)\n",
    "            all_keywords[pos_num] = letter.upper()\n",
    "            keyword_locations[pos_num] = {\n",
    "                'letter': letter.upper(),\n",
    "                'phonetic': phonetic,\n",
    "                'chunk': i,\n",
    "                'time_min': start_min\n",
    "            }\n",
    "            print(f\"      Position {pos_num}: {letter.upper()} ({phonetic})\")\n",
    "    else:\n",
    "        snippet = transcript[:60].replace('\\n', ' ')\n",
    "        print(f\"  - No keywords (sample: {snippet}...)\")\n",
    "    \n",
    "    # Clean up chunk file to save space\n",
    "    os.remove(chunk_file)\n",
    "    \n",
    "    # Progress update every 5 chunks\n",
    "    if (i + 1) % 5 == 0:\n",
    "        elapsed = (time.time() - start_time) / 60\n",
    "        avg_time = elapsed / (i + 1)\n",
    "        remaining = avg_time * (num_chunks - i - 1)\n",
    "        print(f\"\\n  Progress: {i+1}/{num_chunks} ({elapsed:.1f} min elapsed, ~{remaining:.1f} min remaining)\")\n",
    "        print(f\"  Keywords found so far: {len(all_keywords)}\")\n",
    "\n",
    "total_time = (time.time() - start_time) / 60\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"âœ“ Completed in {total_time:.1f} minutes\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if all_keywords:\n",
    "    print(f\"\\nâœ“ Found {len(all_keywords)} keyword letters:\\n\")\n",
    "    \n",
    "    for pos in sorted(all_keywords.keys()):\n",
    "        loc = keyword_locations[pos]\n",
    "        print(f\"  Position {pos}: {loc['letter']} ({loc['phonetic']}) - at {loc['time_min']} min\")\n",
    "    \n",
    "    # Build keyword\n",
    "    max_pos = max(all_keywords.keys())\n",
    "    keyword = \"\"\n",
    "    for i in range(1, max_pos + 1):\n",
    "        keyword += all_keywords.get(i, \"_\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ðŸš© KEYWORD: {keyword}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Check completeness\n",
    "    missing = [i for i in range(1, max_pos + 1) if i not in all_keywords]\n",
    "    if missing:\n",
    "        print(f\"\\nâš  Missing positions: {missing}\")\n",
    "    else:\n",
    "        print(f\"\\nâœ“âœ“âœ“ COMPLETE! âœ“âœ“âœ“\")\n",
    "    \n",
    "    # Save solution\n",
    "    with open('SOLUTION.txt', 'w') as f:\n",
    "        f.write(f\"KEYWORD: {keyword}\\n\\n\")\n",
    "        f.write(\"Letters found:\\n\")\n",
    "        for pos in sorted(all_keywords.keys()):\n",
    "            loc = keyword_locations[pos]\n",
    "            f.write(f\"  Position {pos}: {loc['letter']} ({loc['phonetic']}) at {loc['time_min']} min\\n\")\n",
    "        if missing:\n",
    "            f.write(f\"\\nMissing positions: {missing}\\n\")\n",
    "    \n",
    "    print(\"\\nâœ“ Solution saved to SOLUTION.txt\")\n",
    "    \n",
    "    # Download\n",
    "    from google.colab import files\n",
    "    files.download('SOLUTION.txt')\n",
    "else:\n",
    "    print(\"\\nâš  No keywords found!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

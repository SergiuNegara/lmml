{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roman Numeral Recognition - Complete Solution\n",
    "This notebook performs data cleaning, augmentation, and training in one go.\n",
    "\n",
    "## Instructions:\n",
    "1. Upload this notebook to Google Colab\n",
    "2. Runtime â†’ Change runtime type â†’ Select GPU\n",
    "3. Upload your dataset.zip file when prompted\n",
    "4. Run all cells\n",
    "5. Download the trained model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload and extract dataset\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "print(\"Please upload your dataset folder as a zip file (containing train/ and val/ folders)\")\n",
    "print(\"If you don't have it zipped, you can zip the dataset folder first.\\n\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Extract the uploaded zip\n",
    "for filename in uploaded.keys():\n",
    "    print(f\"Extracting {filename}...\")\n",
    "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')\n",
    "\n",
    "# Check if dataset directory exists\n",
    "if os.path.exists('dataset'):\n",
    "    print(\"âœ“ Dataset extracted successfully!\")\n",
    "else:\n",
    "    print(\"Creating dataset directory structure...\")\n",
    "    # Handle different zip structures\n",
    "    !mkdir -p dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Set random seeds\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Analyze Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images(base_path):\n",
    "    \"\"\"Count images in each class\"\"\"\n",
    "    counts = {}\n",
    "    for class_name in sorted(os.listdir(base_path)):\n",
    "        class_path = os.path.join(base_path, class_name)\n",
    "        if os.path.isdir(class_path) and not class_name.startswith('.'):\n",
    "            images = [f for f in os.listdir(class_path) if not f.startswith('.')]\n",
    "            counts[class_name] = len(images)\n",
    "    return counts\n",
    "\n",
    "train_counts = count_images('dataset/train')\n",
    "val_counts = count_images('dataset/val')\n",
    "\n",
    "print(\"Original Training set:\")\n",
    "for class_name, count in train_counts.items():\n",
    "    print(f\"  {class_name}: {count}\")\n",
    "print(f\"  Total: {sum(train_counts.values())}\\n\")\n",
    "\n",
    "print(\"Original Validation set:\")\n",
    "for class_name, count in val_counts.items():\n",
    "    print(f\"  {class_name}: {count}\")\n",
    "print(f\"  Total: {sum(val_counts.values())}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "axes[0].bar(train_counts.keys(), train_counts.values(), color='steelblue')\n",
    "axes[0].set_title('Original Training Set Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Class')\n",
    "axes[0].set_ylabel('Number of Images')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "axes[1].bar(val_counts.keys(), val_counts.values(), color='coral')\n",
    "axes[1].set_title('Validation Set Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Class')\n",
    "axes[1].set_ylabel('Number of Images')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Detect and Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_features(img_path):\n",
    "    \"\"\"Extract features from an image\"\"\"\n",
    "    img = Image.open(img_path).convert('L')\n",
    "    img_array = np.array(img)\n",
    "    return [\n",
    "        np.mean(img_array),\n",
    "        np.std(img_array),\n",
    "        np.min(img_array),\n",
    "        np.max(img_array),\n",
    "    ]\n",
    "\n",
    "def find_outliers(base_path):\n",
    "    \"\"\"Find potential outliers using IQR method\"\"\"\n",
    "    outliers_info = {}\n",
    "    \n",
    "    for class_name in sorted(os.listdir(base_path)):\n",
    "        class_path = os.path.join(base_path, class_name)\n",
    "        if not os.path.isdir(class_path) or class_name.startswith('.'):\n",
    "            continue\n",
    "        \n",
    "        images = [f for f in os.listdir(class_path) if not f.startswith('.')]\n",
    "        features = []\n",
    "        image_paths = []\n",
    "        \n",
    "        for img_name in images:\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            try:\n",
    "                feat = get_image_features(img_path)\n",
    "                features.append(feat)\n",
    "                image_paths.append(img_path)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        features = np.array(features)\n",
    "        Q1 = np.percentile(features, 25, axis=0)\n",
    "        Q3 = np.percentile(features, 75, axis=0)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        outlier_mask = np.any((features < (Q1 - 1.5 * IQR)) | (features > (Q3 + 1.5 * IQR)), axis=1)\n",
    "        outlier_indices = np.where(outlier_mask)[0]\n",
    "        \n",
    "        outliers_info[class_name] = [image_paths[i] for i in outlier_indices]\n",
    "        print(f\"Class {class_name}: Found {len(outlier_indices)} outliers out of {len(images)} images\")\n",
    "    \n",
    "    return outliers_info\n",
    "\n",
    "print(\"Detecting outliers...\")\n",
    "outliers = find_outliers('dataset/train')\n",
    "total_outliers = sum(len(v) for v in outliers.values())\n",
    "print(f\"\\nTotal outliers detected: {total_outliers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cleaned_dataset(base_path, outliers_dict, output_path, removal_rate=0.3):\n",
    "    \"\"\"Remove outliers to create cleaned dataset\"\"\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    removed_count = 0\n",
    "    kept_count = 0\n",
    "    \n",
    "    for class_name in sorted(os.listdir(base_path)):\n",
    "        class_path = os.path.join(base_path, class_name)\n",
    "        if not os.path.isdir(class_path) or class_name.startswith('.'):\n",
    "            continue\n",
    "        \n",
    "        output_class_path = os.path.join(output_path, class_name)\n",
    "        os.makedirs(output_class_path, exist_ok=True)\n",
    "        \n",
    "        outlier_set = set(outliers_dict.get(class_name, []))\n",
    "        \n",
    "        for img_name in os.listdir(class_path):\n",
    "            if img_name.startswith('.'):\n",
    "                continue\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            \n",
    "            if img_path in outlier_set and random.random() < removal_rate:\n",
    "                removed_count += 1\n",
    "                continue\n",
    "            \n",
    "            shutil.copy(img_path, output_class_path)\n",
    "            kept_count += 1\n",
    "    \n",
    "    print(f\"Cleaned dataset: Kept {kept_count}, Removed {removed_count}\")\n",
    "    return output_path\n",
    "\n",
    "print(\"Creating cleaned dataset...\")\n",
    "cleaned_train = create_cleaned_dataset('dataset/train', outliers, 'dataset_cleaned/train', removal_rate=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Balance Classes with Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(img, aug_type):\n",
    "    \"\"\"Apply augmentation\"\"\"\n",
    "    if aug_type == 'rotate':\n",
    "        return img.rotate(random.randint(-15, 15), fillcolor=255)\n",
    "    elif aug_type == 'brightness':\n",
    "        return ImageEnhance.Brightness(img).enhance(random.uniform(0.7, 1.3))\n",
    "    elif aug_type == 'contrast':\n",
    "        return ImageEnhance.Contrast(img).enhance(random.uniform(0.8, 1.2))\n",
    "    elif aug_type == 'blur':\n",
    "        return img.filter(ImageFilter.GaussianBlur(radius=random.uniform(0.5, 1.5)))\n",
    "    elif aug_type == 'shift':\n",
    "        shift_x = random.randint(-3, 3)\n",
    "        shift_y = random.randint(-3, 3)\n",
    "        return img.transform(img.size, Image.AFFINE, (1, 0, shift_x, 0, 1, shift_y), fillcolor=255)\n",
    "    return img\n",
    "\n",
    "def balance_and_augment(cleaned_path, output_path, target_per_class=280):\n",
    "    \"\"\"Balance all classes to target size\"\"\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    augmentation_types = ['rotate', 'brightness', 'contrast', 'blur', 'shift']\n",
    "    \n",
    "    for class_name in sorted(os.listdir(cleaned_path)):\n",
    "        class_path = os.path.join(cleaned_path, class_name)\n",
    "        if not os.path.isdir(class_path) or class_name.startswith('.'):\n",
    "            continue\n",
    "        \n",
    "        output_class_path = os.path.join(output_path, class_name)\n",
    "        os.makedirs(output_class_path, exist_ok=True)\n",
    "        \n",
    "        images = [f for f in os.listdir(class_path) if not f.startswith('.')]\n",
    "        current_count = len(images)\n",
    "        \n",
    "        # Copy originals\n",
    "        for img_name in images:\n",
    "            shutil.copy(os.path.join(class_path, img_name), output_class_path)\n",
    "        \n",
    "        # Augment to reach target\n",
    "        needed = target_per_class - current_count\n",
    "        if needed > 0:\n",
    "            for i in range(needed):\n",
    "                img_name = random.choice(images)\n",
    "                img = Image.open(os.path.join(class_path, img_name))\n",
    "                aug_img = augment_image(img, random.choice(augmentation_types))\n",
    "                aug_img.save(os.path.join(output_class_path, f\"aug_{i}_{img_name}\"))\n",
    "        \n",
    "        print(f\"Class {class_name}: {current_count} â†’ {target_per_class} (+{needed} augmented)\")\n",
    "\n",
    "print(\"Balancing and augmenting...\")\n",
    "balance_and_augment(cleaned_train, 'dataset_augmented/train', target_per_class=280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy validation set\n",
    "shutil.copytree('dataset/val', 'dataset_augmented/val', dirs_exist_ok=True)\n",
    "\n",
    "# Create data_original for training\n",
    "if os.path.exists('data_original'):\n",
    "    shutil.rmtree('data_original')\n",
    "shutil.copytree('dataset_augmented', 'data_original')\n",
    "\n",
    "print(\"\\nâœ“ Data preparation complete!\")\n",
    "\n",
    "# Final stats\n",
    "final_train = count_images('data_original/train')\n",
    "final_val = count_images('data_original/val')\n",
    "print(f\"\\nFinal Training: {sum(final_train.values())} images\")\n",
    "print(f\"Final Validation: {sum(final_val.values())} images\")\n",
    "print(f\"Total: {sum(final_train.values()) + sum(final_val.values())} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup (from train.py)\n",
    "batch_size = 8\n",
    "directory = \"./data_original\"\n",
    "\n",
    "train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory + \"/train\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(32, 32),\n",
    ")\n",
    "\n",
    "valid = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory + \"/val\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(32, 32),\n",
    ")\n",
    "\n",
    "print(f\"Training batches: {train.cardinality().numpy()}\")\n",
    "print(f\"Validation batches: {valid.cardinality().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model (from train.py)\n",
    "base_model = tf.keras.applications.ResNet50(\n",
    "    input_shape=(32, 32, 3),\n",
    "    include_top=False,\n",
    "    weights=None,\n",
    ")\n",
    "base_model = tf.keras.Model(\n",
    "    base_model.inputs, outputs=[base_model.get_layer(\"conv2_block3_out\").output]\n",
    ")\n",
    "\n",
    "inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "x = tf.keras.applications.resnet.preprocess_input(inputs)\n",
    "x = base_model(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x[0])\n",
    "x = tf.keras.layers.Dense(10)(x)\n",
    "model = tf.keras.Model(inputs, x)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "print(\"\\nModel architecture:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"best_model.weights.h5\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nStarting training...\\n\")\n",
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data=valid,\n",
    "    epochs=5,\n",
    "    callbacks=[checkpoint],\n",
    ")\n",
    "\n",
    "# Load best weights\n",
    "model.load_weights(\"best_model.weights.h5\")\n",
    "\n",
    "# Final evaluation\n",
    "loss, acc = model.evaluate(valid)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FINAL VALIDATION ACCURACY: {acc*100:.2f}%\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if acc >= 0.93:\n",
    "    print(\"\\nðŸŽ‰ EXCELLENT! Achieved >93% - Bonus points!\")\n",
    "elif acc >= 0.90:\n",
    "    print(\"\\nâœ“ SUCCESS! Achieved >90% accuracy!\")\n",
    "else:\n",
    "    print(f\"\\nâš  Close! Need {(0.90-acc)*100:.2f}% more to reach 90%\")\n",
    "\n",
    "# Save for submission\n",
    "model.save_weights(\"task_61.h5\")\n",
    "print(\"\\nWeights saved to: task_61.h5 and best_model.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.axhline(y=0.90, color='r', linestyle='--', label='90% Target')\n",
    "plt.axhline(y=0.93, color='g', linestyle='--', label='93% Bonus')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Download Model Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the trained weights\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Downloading model weights...\")\n",
    "files.download('best_model.weights.h5')\n",
    "files.download('task_61.h5')\n",
    "print(\"\\nâœ“ Download complete! Submit these weights for evaluation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps:\n",
    "\n",
    "1. If accuracy is **>90%**: Submit `best_model.weights.h5` or `task_61.h5`\n",
    "2. If accuracy is **<90%**: Try adjusting:\n",
    "   - Increase `removal_rate` in outlier removal (try 0.4-0.5)\n",
    "   - Increase `target_per_class` for more augmentation (try 300-350)\n",
    "   - Increase training epochs (try 8-10)\n",
    "   - Manually review outliers and remove obvious mislabeled images\n",
    "\n",
    "3. Re-run the relevant cells and retrain!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

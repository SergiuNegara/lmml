{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roman Numeral Recognition - FINAL IMPROVED SOLUTION\n",
    "**Aggressive cleaning + Enhanced augmentation + Fixed errors**\n",
    "\n",
    "## Instructions:\n",
    "1. Upload to Google Colab\n",
    "2. Runtime â†’ Change runtime type â†’ GPU (T4)\n",
    "3. Upload dataset.zip\n",
    "4. Run all cells\n",
    "5. Download trained weights\n",
    "\n",
    "## Improvements:\n",
    "- More aggressive outlier removal (60% vs 30%)\n",
    "- Better augmentation (9 types vs 5)\n",
    "- More training images (300 per class vs 280)\n",
    "- Fixed filename error for weights saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload dataset\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "print(\"Upload your dataset.zip file:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "for filename in uploaded.keys():\n",
    "    print(f\"Extracting {filename}...\")\n",
    "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall('.')\n",
    "\n",
    "print(\"\\nâœ“ Dataset extracted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance, ImageFilter, ImageOps\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"GPU:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Data Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images(base_path):\n",
    "    counts = {}\n",
    "    for class_name in sorted(os.listdir(base_path)):\n",
    "        class_path = os.path.join(base_path, class_name)\n",
    "        if os.path.isdir(class_path) and not class_name.startswith('.'):\n",
    "            images = [f for f in os.listdir(class_path) if not f.startswith('.')]\n",
    "            counts[class_name] = len(images)\n",
    "    return counts\n",
    "\n",
    "def get_advanced_features(img_path):\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        img_array = np.array(img)\n",
    "        return [\n",
    "            np.mean(img_array),\n",
    "            np.std(img_array),\n",
    "            np.median(img_array),\n",
    "            np.percentile(img_array, 25),\n",
    "            np.percentile(img_array, 75),\n",
    "            np.mean(np.abs(np.diff(img_array))),  # edge intensity\n",
    "            np.max(img_array) - np.min(img_array)  # contrast\n",
    "        ]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def find_outliers_advanced(base_path):\n",
    "    \"\"\"Aggressive outlier detection using tighter IQR bounds\"\"\"\n",
    "    outliers_info = {}\n",
    "    \n",
    "    for class_name in sorted(os.listdir(base_path)):\n",
    "        class_path = os.path.join(base_path, class_name)\n",
    "        if not os.path.isdir(class_path) or class_name.startswith('.'):\n",
    "            continue\n",
    "        \n",
    "        images = [f for f in os.listdir(class_path) if not f.startswith('.')]\n",
    "        features = []\n",
    "        image_paths = []\n",
    "        \n",
    "        for img_name in images:\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            feat = get_advanced_features(img_path)\n",
    "            if feat is not None:\n",
    "                features.append(feat)\n",
    "                image_paths.append(img_path)\n",
    "        \n",
    "        features = np.array(features)\n",
    "        Q1 = np.percentile(features, 25, axis=0)\n",
    "        Q3 = np.percentile(features, 75, axis=0)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # Tighter bounds: 1.0 * IQR instead of 1.5\n",
    "        outlier_mask = np.any(\n",
    "            (features < (Q1 - 1.0 * IQR)) | (features > (Q3 + 1.0 * IQR)),\n",
    "            axis=1\n",
    "        )\n",
    "        outlier_indices = np.where(outlier_mask)[0]\n",
    "        outliers_info[class_name] = [image_paths[i] for i in outlier_indices]\n",
    "        \n",
    "        print(f\"Class {class_name}: {len(outlier_indices)} outliers / {len(images)}\")\n",
    "    \n",
    "    return outliers_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cleaned_dataset(base_path, outliers_dict, output_path, removal_rate=0.6):\n",
    "    \"\"\"Remove 60% of detected outliers\"\"\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    removed = 0\n",
    "    kept = 0\n",
    "    \n",
    "    for class_name in sorted(os.listdir(base_path)):\n",
    "        class_path = os.path.join(base_path, class_name)\n",
    "        if not os.path.isdir(class_path) or class_name.startswith('.'):\n",
    "            continue\n",
    "        \n",
    "        output_class_path = os.path.join(output_path, class_name)\n",
    "        os.makedirs(output_class_path, exist_ok=True)\n",
    "        outlier_set = set(outliers_dict.get(class_name, []))\n",
    "        \n",
    "        for img_name in os.listdir(class_path):\n",
    "            if img_name.startswith('.'):\n",
    "                continue\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            \n",
    "            if img_path in outlier_set and random.random() < removal_rate:\n",
    "                removed += 1\n",
    "                continue\n",
    "            \n",
    "            shutil.copy(img_path, output_class_path)\n",
    "            kept += 1\n",
    "    \n",
    "    print(f\"\\nCleaned: Kept {kept}, Removed {removed}\")\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image_improved(img, aug_type):\n",
    "    \"\"\"9 diverse augmentation types\"\"\"\n",
    "    if aug_type == 'rotate_small':\n",
    "        return img.rotate(random.randint(-20, 20), fillcolor=255)\n",
    "    elif aug_type == 'rotate_medium':\n",
    "        return img.rotate(random.choice([-10, -5, 5, 10]), fillcolor=255)\n",
    "    elif aug_type == 'brightness':\n",
    "        return ImageEnhance.Brightness(img).enhance(random.uniform(0.6, 1.4))\n",
    "    elif aug_type == 'contrast':\n",
    "        return ImageEnhance.Contrast(img).enhance(random.uniform(0.7, 1.4))\n",
    "    elif aug_type == 'sharpness':\n",
    "        return ImageEnhance.Sharpness(img).enhance(random.uniform(0.5, 2.0))\n",
    "    elif aug_type == 'blur':\n",
    "        return img.filter(ImageFilter.GaussianBlur(radius=random.uniform(0.3, 2.0)))\n",
    "    elif aug_type == 'shift':\n",
    "        shift_x, shift_y = random.randint(-4, 4), random.randint(-4, 4)\n",
    "        return img.transform(img.size, Image.AFFINE, (1, 0, shift_x, 0, 1, shift_y), fillcolor=255)\n",
    "    elif aug_type == 'zoom':\n",
    "        scale = random.uniform(0.9, 1.1)\n",
    "        w, h = img.size\n",
    "        new_w, new_h = int(w * scale), int(h * scale)\n",
    "        resized = img.resize((new_w, new_h), Image.LANCZOS)\n",
    "        if scale > 1:\n",
    "            left, top = (new_w - w) // 2, (new_h - h) // 2\n",
    "            return resized.crop((left, top, left + w, top + h))\n",
    "        else:\n",
    "            new_img = Image.new(img.mode, (w, h), 255)\n",
    "            new_img.paste(resized, ((w - new_w) // 2, (h - new_h) // 2))\n",
    "            return new_img\n",
    "    elif aug_type == 'combined':\n",
    "        img = augment_image_improved(img, 'rotate_small')\n",
    "        img = augment_image_improved(img, random.choice(['brightness', 'contrast']))\n",
    "        return img\n",
    "    return img\n",
    "\n",
    "def balance_and_augment_improved(cleaned_path, output_path, target_per_class=300):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    aug_types = ['rotate_small', 'rotate_medium', 'brightness', 'contrast',\n",
    "                 'sharpness', 'blur', 'shift', 'zoom', 'combined']\n",
    "    \n",
    "    for class_name in sorted(os.listdir(cleaned_path)):\n",
    "        class_path = os.path.join(cleaned_path, class_name)\n",
    "        if not os.path.isdir(class_path) or class_name.startswith('.'):\n",
    "            continue\n",
    "        \n",
    "        output_class_path = os.path.join(output_path, class_name)\n",
    "        os.makedirs(output_class_path, exist_ok=True)\n",
    "        images = [f for f in os.listdir(class_path) if not f.startswith('.')]\n",
    "        \n",
    "        # Copy originals\n",
    "        for img_name in images:\n",
    "            shutil.copy(os.path.join(class_path, img_name), output_class_path)\n",
    "        \n",
    "        # Augment\n",
    "        needed = target_per_class - len(images)\n",
    "        if needed > 0:\n",
    "            for i in range(needed):\n",
    "                img_name = random.choice(images)\n",
    "                img = Image.open(os.path.join(class_path, img_name))\n",
    "                aug_img = augment_image_improved(img, random.choice(aug_types))\n",
    "                aug_img.save(os.path.join(output_class_path, f\"aug_{i}_{img_name}\"))\n",
    "        \n",
    "        print(f\"Class {class_name}: {len(images)} â†’ {target_per_class} (+{needed})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 1: Detect Outliers\")\n",
    "print(\"=\"*60)\n",
    "outliers = find_outliers_advanced('dataset/train')\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 2: Clean Dataset (Remove 60% of outliers)\")\n",
    "print(\"=\"*60)\n",
    "cleaned = create_cleaned_dataset('dataset/train', outliers, 'cleaned/train', removal_rate=0.6)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3: Balance & Augment (Target: 300 per class)\")\n",
    "print(\"=\"*60)\n",
    "balance_and_augment_improved(cleaned, 'augmented/train', target_per_class=300)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 4: Copy Validation Set\")\n",
    "print(\"=\"*60)\n",
    "shutil.copytree('dataset/val', 'augmented/val', dirs_exist_ok=True)\n",
    "\n",
    "# Create data_original\n",
    "if os.path.exists('data_original'):\n",
    "    shutil.rmtree('data_original')\n",
    "shutil.copytree('augmented', 'data_original')\n",
    "\n",
    "print(\"\\nâœ“ Data preparation complete!\")\n",
    "print(f\"Train: {sum(count_images('data_original/train').values())}\")\n",
    "print(f\"Val: {sum(count_images('data_original/val').values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "batch_size = 8\n",
    "directory = \"./data_original\"\n",
    "\n",
    "train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory + \"/train\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(32, 32),\n",
    ")\n",
    "\n",
    "valid = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory + \"/val\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=[\"i\", \"ii\", \"iii\", \"iv\", \"v\", \"vi\", \"vii\", \"viii\", \"ix\", \"x\"],\n",
    "    shuffle=True,\n",
    "    seed=123,\n",
    "    batch_size=batch_size,\n",
    "    image_size=(32, 32),\n",
    ")\n",
    "\n",
    "print(f\"Training batches: {train.cardinality().numpy()}\")\n",
    "print(f\"Validation batches: {valid.cardinality().numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "base_model = tf.keras.applications.ResNet50(\n",
    "    input_shape=(32, 32, 3),\n",
    "    include_top=False,\n",
    "    weights=None,\n",
    ")\n",
    "base_model = tf.keras.Model(\n",
    "    base_model.inputs, outputs=[base_model.get_layer(\"conv2_block3_out\").output]\n",
    ")\n",
    "\n",
    "inputs = tf.keras.Input(shape=(32, 32, 3))\n",
    "x = tf.keras.applications.resnet.preprocess_input(inputs)\n",
    "x = base_model(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x[0])\n",
    "x = tf.keras.layers.Dense(10)(x)\n",
    "model = tf.keras.Model(inputs, x)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with early stopping\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"best_model.weights.h5\",\n",
    "    monitor=\"val_accuracy\",\n",
    "    mode=\"max\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_accuracy\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING STARTED\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data=valid,\n",
    "    epochs=40,  # Increased from 30\n",
    "    callbacks=[checkpoint, early_stop],\n",
    ")\n",
    "\n",
    "# Load best weights\n",
    "model.load_weights(\"best_model.weights.h5\")\n",
    "\n",
    "# Final evaluation\n",
    "loss, acc = model.evaluate(valid)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"FINAL VALIDATION ACCURACY: {acc*100:.2f}%\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if acc >= 0.93:\n",
    "    print(\"\\nðŸŽ‰ BONUS! Achieved â‰¥93% accuracy!\")\n",
    "    print(\"Expected score: 100 points\")\n",
    "elif acc >= 0.90:\n",
    "    score = 70 + ((acc - 0.90) / 0.03) * 30\n",
    "    print(f\"\\nâœ“ SUCCESS! Achieved â‰¥90% accuracy!\")\n",
    "    print(f\"Expected score: ~{score:.0f} points\")\n",
    "else:\n",
    "    print(f\"\\nâš  Need {(0.90-acc)*100:.2f}% more to reach 90%\")\n",
    "    print(\"Try: increase removal_rate to 0.7, or target_per_class to 350\")\n",
    "\n",
    "# Save weights (FIXED: proper filename)\n",
    "model.save_weights(\"submission.weights.h5\")\n",
    "print(\"\\nWeights saved to: submission.weights.h5 and best_model.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train', linewidth=2)\n",
    "plt.plot(history.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "plt.axhline(y=0.90, color='r', linestyle='--', label='90% Target', alpha=0.7)\n",
    "plt.axhline(y=0.93, color='g', linestyle='--', label='93% Bonus', alpha=0.7)\n",
    "plt.title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train', linewidth=2)\n",
    "plt.plot(history.history['val_loss'], label='Validation', linewidth=2)\n",
    "plt.title('Model Loss', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBest validation accuracy: {max(history.history['val_accuracy'])*100:.2f}%\")\n",
    "print(f\"Final training accuracy: {history.history['accuracy'][-1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download trained weights\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Downloading weights...\")\n",
    "files.download('best_model.weights.h5')\n",
    "files.download('submission.weights.h5')\n",
    "print(\"\\nâœ“ Download complete!\")\n",
    "print(\"Submit 'best_model.weights.h5' for evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If Accuracy < 90%: Try These Adjustments\n",
    "\n",
    "1. **More aggressive cleaning:** Change `removal_rate=0.6` to `0.7` or `0.8`\n",
    "2. **More augmentation:** Change `target_per_class=300` to `350` or `400`\n",
    "3. **More epochs:** Change `epochs=40` to `50` or `60`\n",
    "4. **Manual inspection:** Download extreme_outliers and manually remove bad images\n",
    "\n",
    "Then re-run cells 7-12 to retrain with adjusted parameters."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
